{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get url from  gender and year \n",
    "def boston_url(year, gender):\n",
    "    return f\"https://results.baa.org/{year}/?page=1&event=R&event_main_group=runner&num_results=500&pid=list&pidp=start&search%5Bsex%5D={gender}&search%5Bage_class%5D=%25\"\n",
    "\n",
    "# get list of urls \n",
    "list_of_urls = []\n",
    "for page in range(2018,2024):\n",
    "        url1 = boston_url(page, \"W\")\n",
    "        url2 = boston_url(page, \"M\")\n",
    "        list_of_urls.append(url1)\n",
    "        list_of_urls.append(url2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists for name, place, finish time, sex, and year \n",
    "names = []\n",
    "place = []\n",
    "time = []\n",
    "sex = []\n",
    "year = []\n",
    "\n",
    "for url in list_of_urls:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    gen_text = soup.find_all('li', class_='list-group-item')[0]\n",
    "    sex_curr = gen_text.find('span', class_=\"sex\").text.strip()\n",
    "    year_curr = soup.find('span', class_='hidden-xs').text.strip()\n",
    "    results = soup.find_all('li', class_= 'list-group-item row')\n",
    "    for result in results:\n",
    "        place_elem = result.find('div', class_='list-field type-place place-primary numeric')\n",
    "        place.append(place_elem.text.strip())\n",
    "        name_elem = result.find('h4', class_= 'list-field type-fullname')\n",
    "        names.append(name_elem.text.strip())\n",
    "        time_elem = result.find_all('div', class_='split list-field type-time')\n",
    "        time.append(time_elem[1].text.strip())\n",
    "        sex.append(sex_curr)\n",
    "        year.append(year_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into dataframe \n",
    "boston = pd.DataFrame(list(zip(names, place, time, sex, year)), \n",
    "               columns =['Name', 'Place', 'Time', 'Sex', 'Year']) \n",
    "boston.to_csv('boston_2018_2023.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format is slightly different for 2017 and before\n",
    "list_of_urls = []\n",
    "for page in range(2012,2018):\n",
    "        url1 = boston_url(page, \"W\")\n",
    "        url2 = boston_url(page, \"M\")\n",
    "        list_of_urls.append(url1)\n",
    "        list_of_urls.append(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilykoffman/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "data_all = pd.DataFrame() # initialize df \n",
    "\n",
    "for url in list_of_urls:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # gender = soup.find('div', class_=\"list-info-text\").find('span', class_=\"sex\").text.strip()\n",
    "    gender = re.findall(\"(?<=5D=)(.*)(?=&search)\", url)\n",
    "    year = re.findall(\"(?<=baa.org/)(.*)(?=\\/\\?page)\",url)\n",
    "    table = soup.find('table', class_='list-table')\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "        data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns)\n",
    "    yearcol = year * len(df)\n",
    "    sexcol = gender * len(df)\n",
    "    df['year'] = yearcol \n",
    "    df['sex'] = sexcol\n",
    "\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv('boston_2012_2017.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
