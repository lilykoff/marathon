{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buttons_to_click(num):\n",
    "    # return f'/html/body/main/section/div[2]/div/div/div/div/div[4]/div/div/div/div/ul/li[{num}]/a'\n",
    "    return f'//*[@id=\"resultTable_paginate\"]/ul/li[{num}]/a'\n",
    "\n",
    "def buttons_to_click5(num):\n",
    "    return f'//*[@id=\"resultTable_paginate\"]/ul/li[5]/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[4]/div/div/div[2]/div[2]/div[2]/div[1]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2021\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(2)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,300):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(2)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "data_all.to_csv(\"berlin_2021.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(1)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div[1]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2022\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(2)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(2)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2022.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div[2]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2019\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2019.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[4]/div/div/div[2]/div[2]/div[2]/div[2]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2018\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2018.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div[2]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2017\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2017.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div[2]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2016\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2016.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div[2]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2015\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2015.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/lilykoffman/Downloads/chromedriver\")\n",
    "# Open the webpage\n",
    "url = \"https://www.bmw-berlin-marathon.com/en/impressions/statistics-and-history/results-archive/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH, value=\"/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div[2]/button/span\").click()\n",
    "time.sleep(1)\n",
    "year = Select(driver.find_element(By.ID, value=\"editions\"))\n",
    "year.select_by_value(\"2014\")\n",
    "time.sleep(1)\n",
    "sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "for num in range(2,6):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "for num in range(6,600):\n",
    "    time.sleep(1)\n",
    "    driver.find_element(By.XPATH, value=buttons_to_click5(num)).click()\n",
    "    time.sleep(1)\n",
    "    sources.append(driver.page_source)\n",
    "time.sleep(1)\n",
    "driver.quit()\n",
    "\n",
    "data_all = pd.DataFrame()\n",
    "\n",
    "for source in sources:\n",
    "    soup = BeautifulSoup(source, 'html.parser') \n",
    "    table = soup.find('table', id=\"resultTable\")\n",
    "    columns = []\n",
    "    data = []\n",
    "\n",
    "# Extract column names from the table header (th elements)\n",
    "    header_row = table.find('thead').find('tr')\n",
    "    for header_cell in header_row.find_all('th'):\n",
    "        columns.append(header_cell.text.strip())\n",
    "\n",
    "# Extract data rows from the table body (td elements)\n",
    "    body = table.find('tbody')\n",
    "    for row in body.find_all('tr'):\n",
    "        row_data = []\n",
    "        for cell in row.find_all('td'):\n",
    "            row_data.append(cell.text.strip())\n",
    "            data.append(row_data)\n",
    "    df = pd.DataFrame(data, columns = columns).drop_duplicates()\n",
    "    data_all = data_all.append(df, ignore_index = True)\n",
    "\n",
    "data_all.to_csv(\"berlin_2014.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
